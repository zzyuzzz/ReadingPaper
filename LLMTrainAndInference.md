# LLM的训练与推断

目前比较流行的大模型一般都是自回归模型。在推理时，它类似于RNN，每次计算下一个token的概率。也就是说，如果除去最开始的输入情况下，最终推理长度为n的话，就需要计算n次。但是训练却是并行化的。

在使用transformer库情况下，使用以下函数进行推理:
```python
model.generate()
```
某些基础知识可参照[轻松上手微调大语言模型——QLORA篇](fine_tuningLLM.md)。

虽然推理类似串行模式，但是我们仍然可以优化它，这种后续更新的Blog中会详细解释。

### 为什么基于Transformer的大模型可以并行训练

在注意力层重使用了因果掩码操作。因果掩码（Causal Masking）是一个在序列生成任务中非常重要的概念，特别是在语言模型的训练和推理过程中。它的主要目的是确保模型在预测下一个词时只能使用之前的词，而不能看到后面的词，以防止信息泄露或不合理的预测。例如，对于输入序列 $x = [x_1, x_2, x_3, ..., x_n]$，当模型在预测 $x_t$ 时，因果掩码会遮挡 $x_{t+1}$ 到 $x_n$，确保模型只能看到 $x_1, x_2, ..., x_t$。这样，模型的输出不会依赖于未来的输入，保证了生成过程的一致性。

这也是为什么模型推断时是串行的，每次推断$x_{i+1}$都是基于$x_{1:i}$。
用数学公式形式化来讲：

$$
x_2, x_3, ..., x_{t+1}=f_\theta(x_1, x_2, x_3, ..., x_t)
$$

其中$f_\theta$是以$\theta$为参数的LLM。
